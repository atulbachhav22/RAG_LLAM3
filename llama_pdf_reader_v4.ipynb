{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Document\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from pathlib import Path\n",
    "import os\n",
    "import hashlib\n",
    "from slack_sdk import WebClient\n",
    "from slack_sdk.errors import SlackApiError\n",
    "from slack_bolt.adapter.flask import SlackRequestHandler\n",
    "from slack_bolt import App\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from flask import Flask, request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check to see if Llama has been initialized\n",
    "#llm = Ollama(model=\"llama3.1:latest\")\n",
    "llm = Ollama(model=\"llama3.1:latest\", request_timeout=3000.0)\n",
    "#response = llm.complete(\"What is linear regression?\")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "data_folder= os.path.join(current_dir,\"data\")\n",
    "chroma_client = chromadb.PersistentClient(path=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the existing collection if it exists\n",
    "if \"ollama4\" in chroma_client.list_collections():\n",
    "    chroma_client.delete_collection(\"ollama4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the folder containing the PDFs\n",
    "pdf_folder_path = \"C:\\AI BootCamp\\MyRepo\\RAG_LLAM3\\PDF\"\n",
    "txt_folder_path = \"C:\\AI BootCamp\\MyRepo\\RAG_LLAM3\\TXT\"\n",
    "\n",
    "# Check if the directorys exist\n",
    "if not os.path.isdir(pdf_folder_path):\n",
    "    raise ValueError(f\"Directory {pdf_folder_path} does not exist.\")\n",
    "\n",
    "if not os.path.isdir(txt_folder_path):\n",
    "    raise ValueError(f\"Directory {txt_folder_path} does not exist.\")\n",
    "\n",
    "# Gather all PDF and TXT files in the folder\n",
    "pdf_files = list(Path(pdf_folder_path).glob('*.pdf'))\n",
    "txt_files = list(Path(txt_folder_path).glob('*.txt'))\n",
    "\n",
    "# Initialize a reader to read PDF files\n",
    "pdf_reader = SimpleDirectoryReader(input_dir= pdf_folder_path, recursive=True)\n",
    "txt_reader = SimpleDirectoryReader(input_dir= txt_folder_path, recursive=True)\n",
    "\n",
    "# Custom class to mimic PDF structure for TXT files\n",
    "class TxtDocument:\n",
    "    def __init__(self, text, doc_id):\n",
    "        self.text = text\n",
    "        self.doc_id = doc_id\n",
    "        self.id_ = doc_id  # Add id_ attribute\n",
    "\n",
    "    def get_doc_id(self):\n",
    "        return self.doc_id\n",
    "\n",
    "    def hash(self):\n",
    "        return hashlib.md5(self.text.encode('utf-8')).hexdigest()\n",
    "    \n",
    "    def get_metadata_str(self, mode=None):\n",
    "        if mode:\n",
    "            return f\"Document ID: {self.doc_id}, Mode: {mode}\"\n",
    "        return f\"Document ID: {self.doc_id}\"\n",
    "    \n",
    "    def get_content(self, metadata_mode=None):\n",
    "        if metadata_mode:\n",
    "            return f\"Content: {self.text}, Metadata Mode: {metadata_mode}\"\n",
    "        return self.text\n",
    "    \n",
    "    def as_related_node_info(self):\n",
    "        return {\n",
    "            \"doc_id\": self.doc_id,\n",
    "            \"text\": self.text,\n",
    "            \"metadata\": self.get_metadata_str()\n",
    "        }\n",
    "    \n",
    "# Initialize an empty list to store PDF content\n",
    "all_content = []\n",
    "\n",
    "# Loop through each PDF and TXT file and extract content\n",
    "for pdfs in pdf_reader.iter_data():\n",
    "    for pdf in pdfs:\n",
    "        pdf.text = pdf.text.upper()\n",
    "        all_content.append(pdf)\n",
    "\n",
    "# Loop through each TXT file and extract content\n",
    "for txt_file in txt_files:\n",
    "    with open(txt_file, 'r', encoding='utf-8') as file:\n",
    "        txt_content = file.read()\n",
    "        txt_doc = TxtDocument(text=txt_content.upper(), doc_id=str(txt_file))\n",
    "        all_content.append(Document(text=txt_doc.get_content(), doc_id=txt_doc.get_doc_id()))\n",
    "\n",
    "\n",
    "# Create a unified index\n",
    "#chroma_client = chromadb.EphemeralClient()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Create pipeline for indexing and retrieving documents using vector database\n",
    "chroma_collection = chroma_client.create_collection(\"ollama5\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    all_content, \n",
    "    storage_context=storage_context, \n",
    "    embed_model=embed_model, \n",
    "    transformations=[SentenceSplitter(chunk_size=256, chunk_overlap=10)],\n",
    "    \n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "# Set Slack API credentials\n",
    "SLACK_BOT_TOKEN = os.environ[\"SLACK_BOT_TOKEN\"]\n",
    "SLACK_SIGNING_SECRET = os.environ[\"SLACK_SIGNING_SECRET\"]\n",
    "SLACK_BOT_USER_ID = os.environ[\"SLACK_BOT_USER_ID\"]\n",
    "\n",
    "# Initialize the Slack app\n",
    "app = App(token=SLACK_BOT_TOKEN)\n",
    "\n",
    "# Initialize the Flask app\n",
    "# Flask is a web application framework written in Python\n",
    "flask_app = Flask(__name__)\n",
    "handler = SlackRequestHandler(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U07NH4J03D4\n"
     ]
    }
   ],
   "source": [
    "def get_bot_user_id():\n",
    "    \"\"\"\n",
    "    Get the bot user ID using the Slack API.\n",
    "    Returns:\n",
    "        str: The bot user ID.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the Slack client with your bot token\n",
    "        slack_client = WebClient(token=os.environ[\"SLACK_BOT_TOKEN\"])\n",
    "        response = slack_client.auth_test()\n",
    "        return response[\"user_id\"]\n",
    "    except SlackApiError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "def my_function(text):\n",
    "    \"\"\"\n",
    "    Custom function to process the text and return a response.\n",
    "    In this example, the function converts the input text to uppercase.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to process.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed text.\n",
    "    \"\"\"\n",
    "    response = text.upper()\n",
    "    return response\n",
    "\n",
    "print(get_bot_user_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Prompt Template\n",
    "template = (\n",
    "    \"Imagine you are a professor teaching a class on Artifical Intelligence and \"\n",
    "    \"you answer a student's questions about what you have gone over in previous lectures.\"\n",
    "    \"Here is some context from the Aritifical Intelligence class: \\n\"\n",
    "    \"related to the query::\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"-----------------------------------------\\n\"\n",
    "    \"Considering the above information, \"\n",
    "    \"please respond to the following inquiry:\\n\\n\"\n",
    "    \"Question: {query_str}\\n\\n\"\n",
    "    \"Answer succinctly and ensure your response is \"\n",
    "    \"clear to someone without a deep understaind of Artifical Intelligence.\"\n",
    "    \"The professor's name is Ryan.\"\n",
    ")\n",
    "qa_template = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a text-based Question-Answering task the responds with the top 3 most similar documents\n",
    "query_engine = index.as_query_engine(text_qa_template=qa_template, similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student, I'm happy to help!\n",
      "\n",
      "Your question is not related to Artificial Intelligence, but rather a straightforward inquiry about Rohini Patil's phone number.\n",
      "\n",
      "To answer your question directly: According to the email you provided, Rohini Patil's phone number is +1 704 502 2766.\n"
     ]
    }
   ],
   "source": [
    "print(query_engine.query(\"what is rohinis phone number\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:3000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [24/Sep/2024 14:38:02] \"POST /slack/events HTTP/1.1\" 401 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:38:21] \"POST /slack/events HTTP/1.1\" 401 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:41:09] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:41:09] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:41:33] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:41:51] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:41:56] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:53:46] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:53:49] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:53:50] \"GET / HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:55:22] \"POST /slack/events HTTP/1.1\" 401 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:55:35] \"POST /slack/events HTTP/1.1\" 401 -\n",
      "127.0.0.1 - - [24/Sep/2024 14:55:40] \"POST /slack/events HTTP/1.1\" 401 -\n"
     ]
    }
   ],
   "source": [
    "#Create a Slack WebClient for sending messages\n",
    "@app.event(\"app_mention\")\n",
    "def handle_mentions(body, say):\n",
    "    \"\"\"\n",
    "    Event listener for mentions in Slack.\n",
    "    When the bot is mentioned, this function processes the text and sends a response.\n",
    "\n",
    "    Args:@\n",
    "        body (dict): The event data received from Slack.\n",
    "        say (callable): A function for sending a response to the channel.\n",
    "    \"\"\"\n",
    "    text = body[\"event\"][\"text\"]\n",
    "\n",
    "    mention = f\"<@{SLACK_BOT_USER_ID}>\"\n",
    "    text = text.replace(mention, \"\").strip()\n",
    "\n",
    "    say(\"Great question! Let me find the answer for you.\")\n",
    "    #response = query_engine.query(text)\n",
    "    response = my_function(text)\n",
    "    say(response.response)\n",
    "\n",
    "\n",
    "@flask_app.route(\"/slack/events\", methods=[\"POST\"])\n",
    "def slack_events():\n",
    "    \"\"\"\n",
    "    Route for handling Slack events.\n",
    "    This function passes the incoming HTTP request to the SlackRequestHandler for processing.\n",
    "\n",
    "    Returns:\n",
    "        Response: The result of handling the request.\n",
    "    \"\"\"\n",
    "    return handler.handle(request)\n",
    "\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    flask_app.run(port=3000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
